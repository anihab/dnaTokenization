This repository includes Colab notebooks for building and running a Bacterial DNA tokenizer, as well as analyzing and comparing results.

This code was used for my undergraduate thesis and my contributions to the following publications:
- [Exploring the Embedding Methods in Genomic Language Models](https://www.cs.utah.edu/research/technical-reports/) (My Thesis)
- [A Comparison of Tokenization Impact in Attention Based and State Space Genomic Language Models](https://www.biorxiv.org/content/10.1101/2024.09.09.612081v1)
- 

## Contents

- [1. Generating Random Samples](#1-generating-random-samples)
- [2. Building the Vocabulary](#2-building-the-vocabulary)
- [3. Tokenization](#3-tokenization)
- [4. Statistics and Analysis](#4-statistics-and-analysis)
- [5. Data](#5-data)
- [6. Figures](#6-figures)

## 1. Generating Random Samples

**randomSamples.ipynb** generates a set of random samples and processes files in parallel.

Must define for bacteria and phage:
- input and output directories
- coverage ratio
- minimum and maximum sequence lengths

## 2. Building the Vocabulary

**vocabulary.ipynb** trains a BPE tokenizer on the full bacterial training directory to create the vocabulary json file.
Must define vocabulary size, input data path, and output directory path. The `INPUT_PATH` should be a path to a directory of randomly sampled and processed bacterial fasta files.

### 2.1 Running on Bridges

The bash script **build_vocabulary.sh** runs **build_vocabulary.py** on Bridges. The file paths and vocabulary size parameter are hard-coded in **build_vocabulary.py**. 

```
VOCAB_SIZE=4096
INPUT_PATH="/path/to/bacteria_data"
OUTPUT_PATH="/path/to/output_directory"
```

Running the script will save the vocabulary json file to the `OUTPUT_PATH` as `vocabulary_VOCAB_SIZE.json`.

The `/data` subdirectory includes my output on the bacteria data for vocabulary sizes: 4096, 8192, 32768, 16384.

## 3. Tokenization

**tokenize.ipynb** tokenizes all files given:

- a directory or list of selected bacteria sequences in csv files
- a directory or list of phage sequences in csv files
- a tokenizer (vocabulary json file)

## 4. Statistics and Analysis

**statistics.ipynb** gives a collection of functions to analyze tokenized output and produce figures.

## 5. Data

The `/data` subdirectory includes different sizes of the bacterial DNA vocabulary json files. Additionally contains the vocabulary json files of some other models.

## 6. Figures

The `/figures' subdirectory includes figures generated by **statistics.ipynb** for our model.
