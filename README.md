
This repository includes scripts and Colab notebooks for building and running a Bacterial DNA tokenizer, as well as analyzing and comparing results.

This is implementation of my contributions to ['A Comparison of Tokenization Impact in Attention Based and State Space Genomic Language Models'](https://www.biorxiv.org/content/10.1101/2024.09.09.612081v1). Please kindly cite our paper if you use our code.

This is also the implementation of my undergraduate thesis ['Exploring the Embedding Methods in Genomic Language Models'](https://www.cs.utah.edu/research/technical-reports/).

## Contents

- [1. Generating Random Samples](#1-generating-random-samples)
- [2. Building the Vocabulary](#2-building-the-vocabulary)
- [3. Tokenization](#3-tokenization)
- [4. Statistics and Analysis](#4-statistics-and-analysis)
- [5. Data](#5-data)
- [6. Benchmark](#6-benchmark)
- [7. Figures](#7-figures)

## 1. Generating Random Samples

**randomSamples.ipynb** generates a set of random samples and processes files in parallel.

Must define for bacteria and phage:
- input and output directories
- coverage ratio
- minimum and maximum sequence lengths

## 2. Building the Vocabulary

**vocabulary.ipynb** trains a BPE tokenizer on the full bacterial training directory to create the vocabulary json file.
Must define vocabulary size, input data path, and output directory path. The `INPUT_PATH` should be a path to a directory of randomly sampled and processed bacterial fasta files.

### 2.1 Running on Bridges

The bash script **build_vocabulary.sh** runs **build_vocabulary.py** on Bridges. The file paths and vocabulary size parameter are hard-coded in **build_vocabulary.py**. 

```
VOCAB_SIZE=4096
INPUT_PATH="/path/to/bacteria_data"
OUTPUT_PATH="/path/to/output_directory"
```

Running the script will save the vocabulary json file to the `OUTPUT_PATH` as `vocabulary_VOCAB_SIZE.json`.

The `/data` subdirectory includes my output on the bacteria data for vocabulary sizes: 4096, 8192, 32768, 16384.

## 3. Tokenization

**tokenize.ipynb** tokenizes all files given:

- a directory or list of selected bacteria sequences in csv files
- a directory or list of phage sequences in csv files
- a tokenizer (vocabulary json file)

## 4. Statistics and Analysis

**statistics.ipynb** gives a collection of functions to analyze tokenized output and produce figures.

## 5. Data

The `/data` subdirectory includes different sizes of the bacterial DNA vocabulary json files. Additionally contains the vocabulary json files of some other models.

## 6. Benchmark

The `/benchmark` subdirectory includes scripts to:

- format finetuning datasets to the (sequence, label) format
- create a train-test-dev split for finetuning datasets
- run finetuning tasks to benchmark different models.

*Part of the scripts used run different tasks are forked from a different project and are not included in this repository.*

## 7. Figures

The `/figures' subdirectory includes figures generated by **statistics.ipynb** and **results.ipynb** for our model.
